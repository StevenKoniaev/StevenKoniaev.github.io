---
layout: page
title: Machine Learning
---

*Small* collection of papers I *should* or have read.

Under construction as I round up papers.

## Favorite Papers / Resources

## To Read

- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601?ref=ghost.oxen.ai)
- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903?ref=ghost.oxen.ai)
- [Mastering the game of Go with deep neural networks and tree search](https://www.nature.com/articles/nature16961?ref=ghost.oxen.ai)
- [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401?ref=ghost.oxen.ai)
- [System 2 Attention (is something you might need too)](https://arxiv.org/abs/2311.11829)
- [Neural Ordinary Differential Equations](https://arxiv.org/abs/1806.07366)
- [Brain-To-Text Meta AI](https://scontent-yyz1-1.xx.fbcdn.net/v/t39.2365-6/475464888_600710912891423_9108680259802499048_n.pdf?_nc_cat=102&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=VNE4iRNCZXYQ7kNvgHQoelP&_nc_oc=Adn5I2bi-7f3QX4glE3rS381wt2aCJRNpgQjCf2zMMXEXHsTW7Dc-k6LutiBqrCuI3M&_nc_zt=14&_nc_ht=scontent-yyz1-1.xx&_nc_gid=7YwsTYtLmdtHY3w362yi2Q&oh=00_AYGK-TYVzuBO0eMWymHBIJ-gLBuy8GCr8PcomlrLa0uftA&oe=67E41456)
- [Forward Forward Algorithm](https://arxiv.org/pdf/2212.13345)

## Classical Papers
- [Dropout Paper](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)
- [Batch Normalization Paper](https://arxiv.org/pdf/1502.03167v3)
- [Adam Optimizer Paper](https://arxiv.org/pdf/1412.6980)
- [Yolo Paper](https://arxiv.org/pdf/1506.02640)
- [Analysis of LSTM](https://arxiv.org/pdf/1503.04069)
- [Anylsis of RNN](https://arxiv.org/pdf/1506.02078)
- [RNN Encoder Decoder](https://arxiv.org/pdf/1409.1259)
- [GAN Paper](https://arxiv.org/pdf/1406.2661v1)
- [Attention is All You Need](https://arxiv.org/pdf/1706.03762)
- [Bert Paper](https://arxiv.org/pdf/1810.04805)

## Resources
- [Matrix Calculus Review (Paper)](https://arxiv.org/pdf/1802.01528)
- [Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/)
- [Annotated Mamba](https://srush.github.io/annotated-mamba/hard.html)
- [Colhan's Blog](https://colah.github.io/)
- [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
- [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)

## Repos
- [Omni Parser](https://github.com/microsoft/OmniParser/tree/master)

## Read
- I forget what I read but when I review something I'll put it here and write some notes.
